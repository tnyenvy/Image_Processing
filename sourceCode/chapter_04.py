import streamlit as st
import cv2
import os
import numpy as np
from io import BytesIO
from PIL import Image
import datetime
import matplotlib.pyplot as plt

# ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh g·ªëc v√† ·∫£nh sau x·ª≠ l√Ω
SAVE_PATH_ORIGINAL = r"D:\XuLyAnhSo\DoAnCuoiKy\images\imageProcessing_C04"
SAVE_PATH_PROCESSED = r"D:\XuLyAnhSo\DoAnCuoiKy\images\processedImages"

# T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh sau x·ª≠ l√Ω n·∫øu ch∆∞a t·ªìn t·∫°i
os.makedirs(SAVE_PATH_PROCESSED, exist_ok=True)

def InsertImage(image_file=None, path='default.png', display_column=None):
    """
    X·ª≠ l√Ω ·∫£nh t·∫£i l√™n ho·∫∑c s·ª≠ d·ª•ng ·∫£nh m·∫∑c ƒë·ªãnh t·ª´ ƒë∆∞·ªùng d·∫´n.
    
    Args:
        image_file: File ·∫£nh do ng∆∞·ªùi d√πng t·∫£i l√™n (ho·∫∑c None n·∫øu kh√¥ng c√≥).
        path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh m·∫∑c ƒë·ªãnh (n·∫øu kh√¥ng c√≥ ·∫£nh t·∫£i l√™n).
        display_column: C·ªôt Streamlit ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh (n·∫øu c·∫ßn).

    Returns:
        frame: M·∫£ng NumPy c·ªßa ·∫£nh ƒë√£ x·ª≠ l√Ω.
    """
    global image  # Khai b√°o bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ ·∫£nh
    if image_file is not None:
        # X·ª≠ l√Ω ·∫£nh do ng∆∞·ªùi d√πng t·∫£i l√™n
        image = Image.open(image_file)
        frame = np.array(image)
        if frame.ndim == 3 and frame.shape[2] == 3:  # Ki·ªÉm tra ·∫£nh m√†u
            frame = frame[:, :, :3]  # L·∫•y 3 k√™nh RGB
        if display_column:
            display_column.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n")
        image.close()
    else:
        # S·ª≠ d·ª•ng ·∫£nh m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥ ·∫£nh t·∫£i l√™n
        default_path = os.path.join(SAVE_PATH_ORIGINAL, path)
        if not os.path.exists(default_path):
            st.error(f"Kh√¥ng t√¨m th·∫•y ·∫£nh m·∫∑c ƒë·ªãnh t·∫°i: {default_path}")
            return None
        image = Image.open(default_path)
        frame = np.array(image)
        if display_column:
            display_column.image(image, caption="·∫¢nh M·∫∑c ƒê·ªãnh")
        image.close()
    
    return frame

def display_images(original_img, processed_img, original_caption="·∫¢nh G·ªëc", processed_caption="·∫¢nh ƒê√£ X·ª≠ L√Ω"):
    """H√†m hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω c·∫°nh nhau."""
    col1, col2 = st.columns(2)  # T·∫°o 2 c·ªôt ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
    
    # Ki·ªÉm tra xem original_img c√≥ ph·∫£i l√† ƒë∆∞·ªùng d·∫´n kh√¥ng
    if isinstance(original_img, str):
        with col1:
            st.image(original_img, caption=original_caption, use_container_width=True)
    else:
        with col1:
            st.image(original_img, caption=original_caption, use_container_width=True)
    
    # Ki·ªÉm tra xem processed_img c√≥ ph·∫£i l√† ƒë∆∞·ªùng d·∫´n kh√¥ng
    if isinstance(processed_img, str):
        with col2:
            st.image(processed_img, caption=processed_caption, use_container_width=True)
    else:
        with col2:
            st.image(processed_img, caption=processed_caption, use_container_width=True)

def save_processed_image(img, filename):
    """L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω v√†o th∆∞ m·ª•c."""
    processed_path = os.path.join(SAVE_PATH_PROCESSED, filename)
    if isinstance(img, np.ndarray):
        # Chuy·ªÉn t·ª´ NumPy array sang PIL Image
        if img.dtype == np.float64 or img.dtype == np.float32:
            img = (img * 255).astype(np.uint8)
        result_img = Image.fromarray(img)
        result_img.save(processed_path)
    else:
        # N·∫øu ƒë√£ l√† PIL Image
        img.save(processed_path)
    return processed_path

# 1. H√†m x·ª≠ l√Ω ph·ªï t·∫ßn s·ªë
def compute_spectrum(image):
    """T√≠nh ph·ªï t·∫ßn s·ªë c·ªßa ·∫£nh."""
    try:
        f = np.fft.fft2(image)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)
        return fshift, magnitude_spectrum.astype(np.uint8)
    except Exception as e:
        st.error(f"L·ªói khi t√≠nh ph·ªï t·∫ßn s·ªë: {str(e)}")
        return None, None

def spectrum():
    """Hi·ªÉn th·ªã ph·ªï t·∫ßn s·ªë c·ªßa ·∫£nh."""
    st.header("Ph·ªï t·∫ßn s·ªë c·ªßa ·∫£nh")
    
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['jpg', 'png', 'jpeg'], key="spectrum_uploader")
    
    # X·ª≠ l√Ω ·∫£nh
    if uploaded_file is not None:
        img = InsertImage(uploaded_file)
    else:
        img = InsertImage(None, "1. Spectrum.png")
    
    if img is None:
        return
    
    try:
        # Chuy·ªÉn sang ·∫£nh x√°m n·∫øu l√† ·∫£nh m√†u
        if len(img.shape) == 3:
            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        else:
            img_gray = img
        
        # T√≠nh ph·ªï t·∫ßn s·ªë
        fshift, magnitude_spectrum = compute_spectrum(img_gray)
        
        if fshift is None or magnitude_spectrum is None:
            return
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        col1, col2 = st.columns(2)
        with col1:
            st.image(img, caption="·∫¢nh g·ªëc", use_container_width=True)
        with col2:
            st.image(magnitude_spectrum, caption="Ph·ªï t·∫ßn s·ªë", use_container_width=True)
        
        # L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω
        processed_path = save_processed_image(magnitude_spectrum, "1. Spectrum_processed.png")
        
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")

# 2. H√†m l·ªçc trong mi·ªÅn t·∫ßn s·ªë
def apply_frequency_filter(image, filter_type, cutoff, cutoff2=None, order=1):
    """
    √Åp d·ª•ng b·ªô l·ªçc trong mi·ªÅn t·∫ßn s·ªë cho ·∫£nh ƒë·∫ßu v√†o
    
    Parameters:
    -----------
    image : numpy.ndarray
        ·∫¢nh ƒë·∫ßu v√†o (grayscale)
    filter_type : str
        Lo·∫°i b·ªô l·ªçc: "Low Pass", "High Pass", "Band Pass", "Band Reject", "Butterworth LP", "Butterworth HP", "Gaussian LP", "Gaussian HP"
    cutoff : int
        T·∫ßn s·ªë c·∫Øt ch√≠nh
    cutoff2 : int, optional
        T·∫ßn s·ªë c·∫Øt th·ª© hai (cho l·ªçc Band Pass/Reject)
    order : int, optional
        B·∫≠c c·ªßa b·ªô l·ªçc Butterworth
        
    Returns:
    --------
    tuple
        (mask, filtered_image, spectrum_filtered)
    """
    # Chu·∫©n b·ªã ·∫£nh
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2
    
    # T·∫°o l∆∞·ªõi t·ªça ƒë·ªô
    u = np.arange(rows)
    v = np.arange(cols)
    u, v = np.meshgrid(u - crow, v - ccol, indexing='ij')
    
    # T√≠nh kho·∫£ng c√°ch t·ª´ t√¢m
    d = np.sqrt(u**2 + v**2)
    
    # Tr√°nh chia cho 0
    d = np.maximum(d, 0.1)
    
    # T·∫°o m·∫∑t n·∫° l·ªçc theo lo·∫°i b·ªô l·ªçc
    if filter_type == "Low Pass":
        mask = (d <= cutoff).astype(float)
    elif filter_type == "High Pass":
        mask = (d > cutoff).astype(float)
    elif filter_type == "Band Pass":
        inner_radius = cutoff
        outer_radius = cutoff2 if cutoff2 is not None else cutoff + cutoff//2
        mask = ((d >= inner_radius) & (d <= outer_radius)).astype(float)
    elif filter_type == "Band Reject":
        inner_radius = cutoff
        outer_radius = cutoff2 if cutoff2 is not None else cutoff + cutoff//2
        mask = ((d < inner_radius) | (d > outer_radius)).astype(float)
    elif filter_type == "Butterworth LP":
        mask = 1 / (1 + (d / cutoff)**(2 * order))
    elif filter_type == "Butterworth HP":
        mask = 1 / (1 + (cutoff / d)**(2 * order))
    elif filter_type == "Gaussian LP":
        mask = np.exp(-(d**2) / (2 * cutoff**2))
    elif filter_type == "Gaussian HP":
        mask = 1 - np.exp(-(d**2) / (2 * cutoff**2))
    else:
        mask = np.ones((rows, cols))
    
    # √Åp d·ª•ng FFT
    f = np.fft.fft2(image)
    fshift = np.fft.fftshift(f)
    
    # √Åp d·ª•ng b·ªô l·ªçc
    fshift_filtered = fshift * mask
    
    # T√≠nh ph·ªï sau khi l·ªçc ƒë·ªÉ hi·ªÉn th·ªã
    spectrum_filtered = np.log(np.abs(fshift_filtered) + 1)
    spectrum_filtered = cv2.normalize(spectrum_filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    # Chuy·ªÉn ng∆∞·ª£c l·∫°i mi·ªÅn kh√¥ng gian
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.abs(img_back)
    
    # Chu·∫©n h√≥a k·∫øt qu·∫£
    img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    return mask, img_back, spectrum_filtered

def frequency_domain_filter():
    st.header("L·ªçc trong mi·ªÅn t·∫ßn s·ªë")
    
    # T·∫£i l√™n ·∫£nh
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['jpg', 'png', 'jpeg'], key="filter_uploader")
    
    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn sang grayscale
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        
        if len(img_array.shape) == 3:
            img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            img_gray = img_array
            
        # T·∫°o layout v·ªõi 2 c·ªôt
        main_cols = st.columns([1, 2])
        
        with main_cols[0]:
            st.subheader("ƒêi·ªÅu khi·ªÉn")
            
            # Ch·ªçn lo·∫°i b·ªô l·ªçc
            filter_options = [
                "Low Pass", "High Pass", 
                "Band Pass", "Band Reject", 
                "Butterworth LP", "Butterworth HP", 
                "Gaussian LP", "Gaussian HP"
            ]
            filter_type = st.selectbox("Lo·∫°i b·ªô l·ªçc", filter_options)
            
            # X√°c ƒë·ªãnh gi√° tr·ªã t·ªëi ƒëa cho cutoff d·ª±a tr√™n k√≠ch th∆∞·ªõc ·∫£nh
            max_cutoff = min(img_gray.shape) // 2
            
            # Tham s·ªë c∆° b·∫£n (cutoff ch√≠nh)
            cutoff = st.slider("T·∫ßn s·ªë c·∫Øt", 1, max_cutoff, max_cutoff // 8)
            
            # Tham s·ªë b·ªï sung d·ª±a tr√™n lo·∫°i b·ªô l·ªçc
            cutoff2 = None
            order = 1
            
            if filter_type in ["Band Pass", "Band Reject"]:
                cutoff2 = st.slider("T·∫ßn s·ªë c·∫Øt th·ª© hai", cutoff + 1, max_cutoff, min(cutoff + max_cutoff // 8, max_cutoff))
            
            if filter_type in ["Butterworth LP", "Butterworth HP"]:
                order = st.slider("B·∫≠c c·ªßa b·ªô l·ªçc", 1, 10, 2)
            
            # Hi·ªÉn th·ªã m√¥ t·∫£ b·ªô l·ªçc
            filter_info = {
                "Low Pass": "Gi·ªØ l·∫°i c√°c t·∫ßn s·ªë th·∫•p v√† lo·∫°i b·ªè c√°c t·∫ßn s·ªë cao.",
                "High Pass": "Gi·ªØ l·∫°i c√°c t·∫ßn s·ªë cao v√† lo·∫°i b·ªè c√°c t·∫ßn s·ªë th·∫•p.",
                "Band Pass": "Gi·ªØ l·∫°i c√°c t·∫ßn s·ªë trong m·ªôt d·∫£i nh·∫•t ƒë·ªãnh.",
                "Band Reject": "Lo·∫°i b·ªè c√°c t·∫ßn s·ªë trong m·ªôt d·∫£i nh·∫•t ƒë·ªãnh.",
                "Butterworth LP": "L·ªçc th√¥ng th·∫•p Butterworth v·ªõi s·ª± chuy·ªÉn ti·∫øp m∆∞·ª£t m√†.",
                "Butterworth HP": "L·ªçc th√¥ng cao Butterworth v·ªõi s·ª± chuy·ªÉn ti·∫øp m∆∞·ª£t m√†.",
                "Gaussian LP": "L·ªçc th√¥ng th·∫•p Gaussian, gi·∫£m d·∫ßn m∆∞·ª£t m√† theo ph√¢n ph·ªëi Gaussian.",
                "Gaussian HP": "L·ªçc th√¥ng cao Gaussian, tƒÉng d·∫ßn m∆∞·ª£t m√† theo ph√¢n ph·ªëi Gaussian."
            }
            
            st.info(filter_info.get(filter_type, ""))
        
        # √Åp d·ª•ng b·ªô l·ªçc v·ªõi tham s·ªë ƒë√£ ch·ªçn
        if filter_type in ["Band Pass", "Band Reject"]:
            mask, filtered_image, spectrum_filtered = apply_frequency_filter(img_gray, filter_type, cutoff, cutoff2)
        elif filter_type in ["Butterworth LP", "Butterworth HP"]:
            mask, filtered_image, spectrum_filtered = apply_frequency_filter(img_gray, filter_type, cutoff, order=order)
        else:
            mask, filtered_image, spectrum_filtered = apply_frequency_filter(img_gray, filter_type, cutoff)
        
        # T√≠nh ph·ªï t·∫ßn s·ªë g·ªëc
        _, spectrum_original = compute_spectrum(img_gray)
        
        # Hi·ªÉn th·ªã mask cho m·ª•c ƒë√≠ch tr·ª±c quan
        mask_visual = cv2.normalize(mask, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ trong c·ªôt th·ª© hai
        with main_cols[1]:
            st.subheader("K·∫øt qu·∫£")
            
            # T·∫°o tabs cho c√°c lo·∫°i hi·ªÉn th·ªã kh√°c nhau
            tabs = st.tabs(["·∫¢nh", "Ph·ªï t·∫ßn s·ªë", "M·∫∑t n·∫°"])
            
            with tabs[0]:
                result_cols = st.columns(2)
                with result_cols[0]:
                    st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
                with result_cols[1]:
                    st.image(filtered_image, caption=f"·∫¢nh sau khi l·ªçc {filter_type}", use_container_width=True)
            
            with tabs[1]:
                spectrum_cols = st.columns(2)
                with spectrum_cols[0]:
                    st.image(spectrum_original, caption="Ph·ªï t·∫ßn s·ªë g·ªëc", use_container_width=True)
                with spectrum_cols[1]:
                    st.image(spectrum_filtered, caption="Ph·ªï t·∫ßn s·ªë sau khi l·ªçc", use_container_width=True)
            
            with tabs[2]:
                st.image(mask_visual, caption="M·∫∑t n·∫° b·ªô l·ªçc", use_container_width=True)
        
        # Th√™m n√∫t t·∫£i xu·ªëng ·∫£nh ƒë√£ l·ªçc
        buffered = BytesIO()
        Image.fromarray(filtered_image).save(buffered, format="PNG")
        st.download_button(
            label="üì• T·∫£i xu·ªëng ·∫£nh ƒë√£ l·ªçc",
            data=buffered.getvalue(),
            file_name=f"filtered_{filter_type.lower().replace(' ', '_')}.png",
            mime="image/png"
        )
    else:
        st.info("üëÜ Vui l√≤ng t·∫£i l√™n m·ªôt ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# 3. H√†m √°p d·ª•ng b·ªô l·ªçc Notch-Reject
def notch_reject_filter():
    """UI cho b·ªô l·ªçc Notch-Reject."""
    st.header("B·ªô l·ªçc Notch-Reject")
   
    # Tab cho c√°c ch·ª©c nƒÉng kh√°c nhau
    tab_names = ["L·ªçc ·∫£nh", "V·∫Ω b·ªô l·ªçc"]
    tab_selected = st.radio("Ch·ªçn ch·ª©c nƒÉng:", tab_names, horizontal=True)
   
    if tab_selected == "L·ªçc ·∫£nh":
        # Ch·ªçn gi·ªØa upload ·∫£nh ho·∫∑c d√πng ·∫£nh m·∫´u
        col1, col2 = st.columns([1, 1])
        with col1:
            uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['jpg', 'png', 'jpeg'], key="notch_uploader")
        with col2:
            use_sample = st.checkbox("S·ª≠ d·ª•ng ·∫£nh m·∫´u", value=False)
       
        # X·ª≠ l√Ω ·∫£nh
        if uploaded_file is not None:
            img = InsertImage(uploaded_file)
        elif use_sample:
            img = InsertImage(None, "3. B·ªô l·ªçc Notch.png")
        else:
            st.info("Vui l√≤ng t·∫£i l√™n ·∫£nh ho·∫∑c ch·ªçn s·ª≠ d·ª•ng ·∫£nh m·∫´u")
            return
       
        if img is None:
            return
           
        try:
            # Chuy·ªÉn sang ·∫£nh x√°m
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            else:
                img_gray = img
           
            # T√≠nh ph·ªï t·∫ßn s·ªë
            _, magnitude_spectrum = compute_spectrum(img_gray)
           
            # Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ph·ªï t·∫ßn s·ªë
            col1, col2 = st.columns(2)
            with col1:
                st.image(img, caption="·∫¢nh g·ªëc", use_container_width=True)
            with col2:
                st.image(magnitude_spectrum, caption="Ph·ªï t·∫ßn s·ªë", use_container_width=True)
           
            # UI cho vi·ªác t·ª± ƒë·ªông ph√°t hi·ªán ƒëi·ªÉm notch
            auto_detect = st.checkbox("T·ª± ƒë·ªông ph√°t hi·ªán ƒëi·ªÉm nhi·ªÖu", value=True)
           
            # K√≠ch th∆∞·ªõc ·∫£nh v√† t·ªça ƒë·ªô t√¢m
            rows, cols = img_gray.shape
            crow, ccol = rows // 2, cols // 2
           
            if auto_detect:
                # Tham s·ªë cho vi·ªác ph√°t hi·ªán t·ª± ƒë·ªông
                col1, col2 = st.columns(2)
                with col1:
                    detection_threshold = st.slider("Ng∆∞·ª°ng ph√°t hi·ªán", 50, 250, 200)
                    min_distance = st.slider("Kho·∫£ng c√°ch t·ªëi thi·ªÉu t·ª´ t√¢m", 5, 100, 20)
                with col2:
                    max_points = st.slider("S·ªë ƒëi·ªÉm notch t·ªëi ƒëa", 1, 10, 5)
               
                # T√¨m c√°c ƒëi·ªÉm c√≥ gi√° tr·ªã ph·ªï cao
                high_value_points = np.where(magnitude_spectrum > detection_threshold)
               
                # L·ªçc v√† s·∫Øp x·∫øp c√°c ƒëi·ªÉm
                notch_points = []
                for y, x in zip(high_value_points[0], high_value_points[1]):
                    dy, dx = y - crow, x - ccol
                    distance = np.sqrt(dy**2 + dx**2)
                    if distance >= min_distance:
                        notch_points.append((dy, dx))
               
                # S·∫Øp x·∫øp theo kho·∫£ng c√°ch v√† l·∫•y c√°c ƒëi·ªÉm xa nh·∫•t
                notch_points.sort(key=lambda p: p[0]**2 + p[1]**2, reverse=True)
                notch_points = notch_points[:max_points]
               
                # V·∫Ω c√°c ƒëi·ªÉm ƒë√£ ph√°t hi·ªán
                spectrum_with_points = cv2.cvtColor(magnitude_spectrum, cv2.COLOR_GRAY2RGB)
                for dy, dx in notch_points:
                    y, x = crow + dy, ccol + dx
                    cv2.circle(spectrum_with_points, (x, y), 5, (0, 0, 255), -1)
                    cv2.circle(spectrum_with_points, (2*ccol - x, 2*crow - y), 5, (0, 255, 0), -1)
               
                st.image(spectrum_with_points, caption="Ph·ªï v·ªõi c√°c ƒëi·ªÉm notch ƒë√£ ph√°t hi·ªán", use_container_width=True)
               
            else:
                # UI cho vi·ªác ch·ªçn ƒëi·ªÉm th·ªß c√¥ng
                num_notches = st.number_input("S·ªë l∆∞·ª£ng c·∫∑p ƒëi·ªÉm notch", min_value=1, max_value=5, value=1)
               
                notch_points = []
                for i in range(num_notches):
                    col1, col2 = st.columns(2)
                    with col1:
                        y_offset = st.slider(f"Notch {i+1}: Y-offset t·ª´ t√¢m", -crow, crow, 0, key=f"y_offset_{i}")
                    with col2:
                        x_offset = st.slider(f"Notch {i+1}: X-offset t·ª´ t√¢m", -ccol, ccol, 0, key=f"x_offset_{i}")
                    notch_points.append((y_offset, x_offset))
           
            # Tham s·ªë cho b·ªô l·ªçc
            d0 = st.slider("B√°n k√≠nh b·ªô l·ªçc Notch", 1, 50, 10)
           
            # √Åp d·ª•ng b·ªô l·ªçc khi ng∆∞·ªùi d√πng nh·∫•n n√∫t
            if st.button("√Åp d·ª•ng b·ªô l·ªçc"):
                # √Åp d·ª•ng b·ªô l·ªçc
                mask, filtered_image = apply_notch_reject_filter(img_gray, notch_points, d0)
               
                if filtered_image is not None:
                    # T√≠nh ph·ªï c·ªßa ·∫£nh sau khi l·ªçc
                    _, spectrum_filtered = compute_spectrum(filtered_image)
                   
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ trong tabs
                    result_tabs = st.tabs(["·∫¢nh k·∫øt qu·∫£", "Ph·ªï t·∫ßn s·ªë"])
                   
                    with result_tabs[0]:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.image(img_gray, caption="·∫¢nh g·ªëc", use_container_width=True)
                        with col2:
                            st.image(filtered_image, caption="·∫¢nh sau khi l·ªçc", use_container_width=True)
                   
                    with result_tabs[1]:
                        col1, col2 = st.columns(2)
                        with col1:
                            mask_display = cv2.normalize(mask, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
                            st.image(mask_display, caption="M·∫∑t n·∫° b·ªô l·ªçc", use_container_width=True)
                        with col2:
                            st.image(spectrum_filtered, caption="Ph·ªï sau khi l·ªçc", use_container_width=True)
                   
                    # So s√°nh chi ti·∫øt
                    if st.checkbox("Hi·ªÉn th·ªã so s√°nh chi ti·∫øt"):
                        size = min(rows, cols) // 4
                        crop_original = img_gray[crow-size:crow+size, ccol-size:ccol+size]
                        crop_filtered = filtered_image[crow-size:crow+size, ccol-size:ccol+size]
                       
                        col1, col2 = st.columns(2)
                        with col1:
                            st.image(crop_original, caption="Chi ti·∫øt ·∫£nh g·ªëc", use_container_width=True)
                        with col2:
                            st.image(crop_filtered, caption="Chi ti·∫øt ·∫£nh ƒë√£ l·ªçc", use_container_width=True)
                   
                    # L∆∞u k·∫øt qu·∫£
                    if st.button("L∆∞u k·∫øt qu·∫£"):
                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"notch_filtered_{timestamp}.png"
                        save_processed_image(filtered_image, filename)
                        st.success(f"ƒê√£ l∆∞u ·∫£nh t·∫°i: {os.path.join(SAVE_PATH_PROCESSED, filename)}")
       
        except Exception as e:
            st.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
   
    elif tab_selected == "V·∫Ω b·ªô l·ªçc":
        # S·ª≠ d·ª•ng giao di·ªán ri√™ng cho v·∫Ω b·ªô l·ªçc
        draw_notch_filter_ui()


def CreateNotchRejectFilter(P=250, Q=180, D0=10, n=2, notch_points=None):
    """
    T·∫°o b·ªô l·ªçc Notch-Reject d·ª±a tr√™n c√°c ƒëi·ªÉm notch ƒë√£ cho.
    
    Args:
        P, Q: K√≠ch th∆∞·ªõc b·ªô l·ªçc (m·∫∑c ƒë·ªãnh 250x180)
        D0: B√°n k√≠nh c·ªßa b·ªô l·ªçc (m·∫∑c ƒë·ªãnh 10)
        n: B·∫≠c c·ªßa b·ªô l·ªçc (m·∫∑c ƒë·ªãnh 2)
        notch_points: Danh s√°ch c√°c ƒëi·ªÉm notch (u, v) (m·∫∑c ƒë·ªãnh l√† None v√† s·∫Ω s·ª≠ d·ª•ng c√°c ƒëi·ªÉm c·ªë ƒë·ªãnh)
        
    Returns:
        H: M·∫∑t n·∫° b·ªô l·ªçc
    """
    # S·ª≠ d·ª•ng c√°c ƒëi·ªÉm m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥ ƒëi·ªÉm n√†o ƒë∆∞·ª£c cung c·∫•p
    if notch_points is None:
        notch_points = [
            (44, 58),
            (40, 119),
            (86, 59),
            (82, 119)
        ]
    
    H = np.ones((P, Q), np.float32)
    
    for u in range(0, P):
        for v in range(0, Q):
            h = 1.0
            
            # √Åp d·ª•ng b·ªô l·ªçc cho m·ªói ƒëi·ªÉm notch
            for u_notch, v_notch in notch_points:
                # B·ªô l·ªçc cho ƒëi·ªÉm g·ªëc
                Duv = np.sqrt((u-u_notch)**2 + (v-v_notch)**2)
                if Duv > 0:
                    h = h*1.0/(1.0 + np.power(D0/Duv, 2*n))
                else:
                    h = h*0.0
                
                # B·ªô l·ªçc cho ƒëi·ªÉm ƒë·ªëi x·ª©ng
                Duv = np.sqrt((u-(P-u_notch))**2 + (v-(Q-v_notch))**2)
                if Duv > 0:
                    h = h*1.0/(1.0 + np.power(D0/Duv, 2*n))
                else:
                    h = h*0.0
                    
            H[u,v] = h
            
    return H


def DrawNotchRejectFilter(H=None, L=128):
    """
    Tr·ª±c quan h√≥a b·ªô l·ªçc Notch-Reject.
    
    Args:
        H: M·∫∑t n·∫° b·ªô l·ªçc (n·∫øu None, s·∫Ω t·∫°o m·∫∑t n·∫° m·ªõi)
        L: Gi√° tr·ªã c∆∞·ªùng ƒë·ªô t·ªëi ƒëa (ƒë·ªô t∆∞∆°ng ph·∫£n) (m·∫∑c ƒë·ªãnh 128)
        
    Returns:
        filter_visualization: H√¨nh ·∫£nh tr·ª±c quan c·ªßa b·ªô l·ªçc
    """
    # T·∫°o b·ªô l·ªçc n·∫øu ch∆∞a ƒë∆∞·ª£c cung c·∫•p
    if H is None:
        H = CreateNotchRejectFilter()
        
    # Chuy·ªÉn ƒë·ªïi b·ªô l·ªçc th√†nh h√¨nh ·∫£nh c√≥ th·ªÉ hi·ªÉn th·ªã
    H_display = H*(L-1)
    H_display = H_display.astype(np.uint8)
    
    # T·∫°o h√¨nh ·∫£nh m√†u ƒë·ªÉ tr·ª±c quan h√≥a t·ªët h∆°n
    filter_color = cv2.applyColorMap(H_display, cv2.COLORMAP_JET)
    
    return filter_color


def draw_notch_filter_ui():
    """UI chuy√™n bi·ªát cho vi·ªác v·∫Ω b·ªô l·ªçc Notch-Reject."""
    st.subheader("V·∫Ω b·ªô l·ªçc Notch-Reject")
   
    # Tham s·ªë cho v·∫Ω b·ªô l·ªçc
    col1, col2 = st.columns(2)
    with col1:
        P = st.slider("Chi·ªÅu cao b·ªô l·ªçc", 100, 500, 250, step=10)
        Q = st.slider("Chi·ªÅu r·ªông b·ªô l·ªçc", 100, 500, 180, step=10)
        D0 = st.slider("B√°n k√≠nh b·ªô l·ªçc", 1, 50, 10, key="draw_d0")
    with col2:
        n = st.slider("B·∫≠c c·ªßa b·ªô l·ªçc", 1, 10, 2)
        L = st.slider("ƒê·ªô t∆∞∆°ng ph·∫£n", 1, 255, 128)
   
    # UI cho ch·ªçn ƒëi·ªÉm notch
    st.subheader("C·∫•u h√¨nh ƒëi·ªÉm Notch")
    use_custom_points = st.checkbox("T√πy ch·ªânh ƒëi·ªÉm Notch", value=False)
    
    if use_custom_points:
        num_notches = st.number_input("S·ªë l∆∞·ª£ng c·∫∑p ƒëi·ªÉm notch", min_value=1, max_value=5, value=2, key="draw_num_notches")
        
        notch_points = []
        for i in range(num_notches):
            col1, col2 = st.columns(2)
            with col1:
                u = st.slider(f"Notch {i+1}: U", 0, P-1, min(44 + i*10, P-1), key=f"draw_u_{i}")
            with col2:
                v = st.slider(f"Notch {i+1}: V", 0, Q-1, min(58 + i*10, Q-1), key=f"draw_v_{i}")
            notch_points.append((u, v))
    else:
        # S·ª≠ d·ª•ng c√°c ƒëi·ªÉm m·∫´u c·ªë ƒë·ªãnh
        notch_points = [
            (44, 58),
            (40, 119),
            (86, 59),
            (82, 119)
        ]
        # Hi·ªÉn th·ªã c√°c ƒëi·ªÉm m·∫´u
        st.info("S·ª≠ d·ª•ng c√°c ƒëi·ªÉm Notch m·∫´u:")
        for i, (u, v) in enumerate(notch_points):
            st.write(f"Notch {i+1}: U={u}, V={v}")
   
    # V·∫Ω b·ªô l·ªçc khi ng∆∞·ªùi d√πng nh·∫•n n√∫t
    if st.button("V·∫Ω b·ªô l·ªçc"):
        with st.spinner("ƒêang v·∫Ω b·ªô l·ªçc..."):
            # V·∫Ω b·ªô l·ªçc s·ª≠ d·ª•ng c√°c th√¥ng s·ªë ƒë√£ ch·ªçn
            H = CreateNotchRejectFilter(P, Q, D0, n, notch_points)
            filter_visualization = DrawNotchRejectFilter(H, L)
           
            if filter_visualization is not None:
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.image(filter_visualization, caption="B·ªô l·ªçc Notch-Reject", use_container_width=True)
               
                # Th√¥ng tin v·ªÅ c√°c ƒëi·ªÉm notch
                st.subheader("Th√¥ng tin b·ªô l·ªçc")
                st.write(f"K√≠ch th∆∞·ªõc b·ªô l·ªçc: {P}x{Q}")
                st.write(f"B√°n k√≠nh b·ªô l·ªçc (D0): {D0}")
                st.write(f"B·∫≠c c·ªßa b·ªô l·ªçc (n): {n}")
                st.write(f"S·ªë l∆∞·ª£ng c·∫∑p ƒëi·ªÉm notch: {len(notch_points)}")
               
                # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ c√°c ƒëi·ªÉm
                st.write("Chi ti·∫øt ƒëi·ªÉm notch:")
                for i, (u, v) in enumerate(notch_points):
                    st.write(f"- Notch {i+1}: U={u}, V={v}")
               
                # L∆∞u k·∫øt qu·∫£
                if st.button("L∆∞u b·ªô l·ªçc"):
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"notch_filter_{timestamp}.png"
                    save_processed_image(filter_visualization, filename)
                    st.success(f"ƒê√£ l∆∞u b·ªô l·ªçc t·∫°i: {os.path.join(SAVE_PATH_PROCESSED, filename)}")


def apply_notch_reject_filter(img, notch_points, D0, n=2):
    """
    √Åp d·ª•ng b·ªô l·ªçc Notch-Reject l√™n ·∫£nh.
    
    Args:
        img: ·∫¢nh ƒë·∫ßu v√†o
        notch_points: Danh s√°ch c√°c ƒëi·ªÉm notch (y_offset, x_offset) t·ª´ t√¢m
        D0: B√°n k√≠nh b·ªô l·ªçc
        n: B·∫≠c c·ªßa b·ªô l·ªçc (m·∫∑c ƒë·ªãnh l√† 2)
        
    Returns:
        mask: M·∫∑t n·∫° b·ªô l·ªçc
        filtered_image: ·∫¢nh sau khi l·ªçc
    """
    # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
    rows, cols = img.shape
    crow, ccol = rows // 2, cols // 2
    
    # T·∫°o DFT
    dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    
    # T·∫°o m·∫∑t n·∫° v·ªõi t·∫•t c·∫£ c√°c gi√° tr·ªã l√† 1
    mask = np.ones((rows, cols, 2), np.float32)
    
    # √Åp d·ª•ng b·ªô l·ªçc notch-reject cho t·ª´ng ƒëi·ªÉm
    for y_offset, x_offset in notch_points:
        # T·ªça ƒë·ªô ƒëi·ªÉm notch
        y, x = crow + y_offset, ccol + x_offset
        y_sym, x_sym = crow - y_offset, ccol - x_offset
        
        # √Åp d·ª•ng b·ªô l·ªçc Butterworth notch-reject
        for u in range(rows):
            for v in range(cols):
                # T√≠nh kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm (u,v) ƒë·∫øn ƒëi·ªÉm notch
                Duv1 = np.sqrt((u-y)**2 + (v-x)**2)
                Duv2 = np.sqrt((u-y_sym)**2 + (v-x_sym)**2)
                
                # √Åp d·ª•ng c√¥ng th·ª©c b·ªô l·ªçc Butterworth
                if Duv1 > 0:
                    mask[u,v] *= 1.0/(1.0 + np.power(D0/Duv1, 2*n))
                else:
                    mask[u,v] *= 0.0
                    
                if Duv2 > 0:
                    mask[u,v] *= 1.0/(1.0 + np.power(D0/Duv2, 2*n))
                else:
                    mask[u,v] *= 0.0
    
    # √Åp d·ª•ng m·∫∑t n·∫° v√† th·ª±c hi·ªán DFT ng∆∞·ª£c
    fshift = dft_shift * mask
    f_ishift = np.fft.ifftshift(fshift)
    img_back = cv2.idft(f_ishift)
    img_back = cv2.magnitude(img_back[:,:,0], img_back[:,:,1])
    
    # Chu·∫©n h√≥a ·∫£nh k·∫øt qu·∫£
    img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    return mask[:,:,0], img_back

# 4. H√†m x√≥a nhi·ªÖu Moire
def remove_moire(image, r_low=30, r_high=None, strength=1.0):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2
    
    # Chuy·ªÉn sang mi·ªÅn t·∫ßn s·ªë
    dft = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    
    # T·∫°o m·∫∑t n·∫° cho l·ªçc th√¥ng th·∫•p (gi·ªØ t·∫ßn s·ªë th·∫•p)
    mask = np.ones((rows, cols, 2), np.float32)
    
    # T·∫°o l∆∞·ªõi t·ªça ƒë·ªô
    u = np.arange(rows)
    v = np.arange(cols)
    u, v = np.meshgrid(u - crow, v - ccol, indexing='ij')
    d = np.sqrt(u**2 + v**2)
    
    # √Åp d·ª•ng l·ªçc th√¥ng th·∫•p
    if r_high is None:
        # √Åp d·ª•ng Butterworth lowpass filter
        n = 2  # Order c·ªßa b·ªô l·ªçc Butterworth
        filter_low = 1 / (1 + (d / r_low)**(2*n))
    else:
        # √Åp d·ª•ng band-reject filter
        filter_low = 1 - np.exp(-0.5 * ((d**2 - r_low**2) / (d * r_high))**2)
    
    # √Åp d·ª•ng m·∫∑t n·∫°
    mask[:, :, 0] = mask[:, :, 0] * filter_low
    mask[:, :, 1] = mask[:, :, 1] * filter_low
    
    # K·∫øt h·ª£p m·∫∑t n·∫° v·ªõi m·ª©c ƒë·ªô m·∫°nh y·∫øu
    blended_mask = np.ones((rows, cols, 2), np.float32) * (1 - strength) + mask * strength
    
    # √Åp d·ª•ng m·∫∑t n·∫° v√†o ·∫£nh trong mi·ªÅn t·∫ßn s·ªë
    fshift_filtered = dft_shift * blended_mask
    
    # Chuy·ªÉn v·ªÅ mi·ªÅn kh√¥ng gian
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = cv2.idft(f_ishift)
    img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])
    
    # Chu·∫©n h√≥a k·∫øt qu·∫£
    img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    return filter_low, img_back

def remove_moire_ui():
    """UI cho x√≥a nhi·ªÖu Moire."""
    st.header("X√≥a nhi·ªÖu Moire")
    
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['jpg', 'png', 'jpeg'], key="moire_uploader")
    
    if uploaded_file is not None:
        try:
            # ƒê·ªçc ·∫£nh
            image = Image.open(uploaded_file)
            img_array = np.array(image)
            
            # Ki·ªÉm tra ·∫£nh m√†u v√† ƒë·ªãnh d·∫°ng
            is_color = len(img_array.shape) == 3 and img_array.shape[2] >= 3
            
            # Tham s·ªë cho b·ªô l·ªçc
            r_low = st.slider("B√°n k√≠nh t·∫ßn s·ªë th·∫•p (gi·ªØ l·∫°i)", 10, 100, 30)
            filter_type = st.radio("Lo·∫°i b·ªô l·ªçc", ["Lowpass", "Band-reject"])
            
            r_high = None
            if filter_type == "Band-reject":
                r_high = st.slider("ƒê·ªô r·ªông bƒÉng t·∫ßn reject", 5, 50, 20)
            
            strength = st.slider("M·ª©c ƒë·ªô l·ªçc", 0.0, 1.0, 0.8)
            
            # X·ª≠ l√Ω ·∫£nh m√†u ho·∫∑c grayscale
            if is_color:
                # Chuy·ªÉn ƒë·ªïi ·∫£nh sang ƒë√∫ng ƒë·ªãnh d·∫°ng
                if img_array.shape[2] == 4:  # N·∫øu c√≥ k√™nh alpha
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
                
                # T√°ch v√† x·ª≠ l√Ω t·ª´ng k√™nh m√†u
                channels = cv2.split(img_array)
                filtered_channels = []
                masks = []
                
                for channel in channels:
                    mask, filtered_channel = remove_moire(channel, r_low, r_high, strength)
                    filtered_channels.append(filtered_channel)
                    masks.append(mask)
                
                # Gh√©p c√°c k√™nh m√†u ƒë√£ x·ª≠ l√Ω
                filtered_image = cv2.merge(filtered_channels)
                mask = masks[0]  # S·ª≠ d·ª•ng m·∫∑t n·∫° c·ªßa k√™nh ƒë·∫ßu ti√™n ƒë·ªÉ hi·ªÉn th·ªã
            else:
                # X·ª≠ l√Ω ·∫£nh grayscale
                img_gray = img_array
                mask, filtered_image = remove_moire(img_gray, r_low, r_high, strength)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
                st.image(mask * 255, caption="M·∫∑t n·∫° b·ªô l·ªçc", use_container_width=True, clamp=True)
            
            with col2:
                st.image(filtered_image, caption="·∫¢nh sau khi x√≥a nhi·ªÖu Moire", use_container_width=True)
                
                # Ph·∫ßn hi·ªÉn th·ªã chi ti·∫øt ph√≥ng to
                if st.checkbox("Hi·ªÉn th·ªã ph√≥ng to chi ti·∫øt"):
                    zoom_factor = st.slider("ƒê·ªô ph√≥ng ƒë·∫°i", 1, 5, 2)
                    height, width = img_array.shape[:2]
                    center_y, center_x = height // 2, width // 2
                    crop_size = min(height, width) // (zoom_factor * 2)
                    
                    # C·∫Øt v√πng trung t√¢m c·ªßa ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω
                    crop_original = img_array[center_y-crop_size:center_y+crop_size,
                                           center_x-crop_size:center_x+crop_size]
                    crop_filtered = filtered_image[center_y-crop_size:center_y+crop_size,
                                                center_x-crop_size:center_x+crop_size]
                    
                    st.image(crop_original, caption="V√πng trung t√¢m ·∫£nh g·ªëc", use_container_width=True)
                    st.image(crop_filtered, caption="V√πng trung t√¢m ·∫£nh ƒë√£ l·ªçc", use_container_width=True)
                    
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
            st.error("Vui l√≤ng th·ª≠ l·∫°i v·ªõi ·∫£nh kh√°c ho·∫∑c ki·ªÉm tra ƒë·ªãnh d·∫°ng ·∫£nh")


# Dictionary √°nh x·∫° ch·ª©c nƒÉng
chapter_04_functions = {
    "Spectrum": spectrum,
    "L·ªçc trong mi·ªÅn t·∫ßn s·ªë": frequency_domain_filter,
    "B·ªô l·ªçc notch-reject": notch_reject_filter, 
    "X√≥a nhi·ªÖu Moire": remove_moire_ui,
}